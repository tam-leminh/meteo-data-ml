{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib.patches import Path, PathPatch\n",
    "import time, datetime\n",
    "import CustomKernels, CustomModels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "##Formatting functions\n",
    "def format_for_learning(xlat, xlon, temp):\n",
    "    X = np.column_stack((xlat, xlon))\n",
    "    Y = np.asarray(temp).reshape(len(temp),1)\n",
    "    return X, Y\n",
    "\n",
    "def format_grid_for_prediction(ylat, ylon):\n",
    "    grid = np.column_stack((np.hstack((ylat)),np.hstack((ylon))))\n",
    "    return grid\n",
    "    \n",
    "def format_prediction_to_grid(prediction, nrow, ncol):\n",
    "    matrix = np.reshape(prediction, (nrow,ncol))  \n",
    "    return matrix\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    report_path = \"\"\n",
    "    data_path = \"data/current-version/\"\n",
    "    datafile = \"\"\n",
    "    report = False\n",
    "    verbose = False\n",
    "    \n",
    "    def __init__(self, data_path=\"data/current-version/\", data_file=None, verbose=False, report=False):\n",
    "        if report:\n",
    "            self.create_report_folder()\n",
    "        self.data_path = data_path\n",
    "        if not data_file is None:\n",
    "            self.load_data(data_file)\n",
    "        self.verbose = verbose\n",
    "        self.report = report\n",
    "\n",
    "    def load_data(self, filename):\n",
    "        self.datafile = filename\n",
    "        df = pd.read_csv(self.data_path + self.datafile, ',')\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "        self.X_all = df[['Lat', 'Lon']].values\n",
    "        self.y_all = df[['Temp']].values\n",
    "\n",
    "    def create_report_folder(self):\n",
    "        t = datetime.datetime.now()\n",
    "        self.report_path = 'reports/{0:%Y_%m_%d-%H_%M_%S}'.format(t)\n",
    "        os.mkdir(self.report_path)\n",
    "\n",
    "    def export_report(self, df, report_type):\n",
    "        df.to_csv(self.report_path + '/%s_%s.csv' % (report_type, name))\n",
    "\n",
    "    def partition_train_test(self, test_size=0.2):\n",
    "        if self.verbose:\n",
    "            print(\"Partition data into train and test samples\")\n",
    "            \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X_all, \n",
    "                                                                                self.y_all, test_size=0.2)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Number of train samples: \" + str(self.X_train.shape[0]))\n",
    "            print(\"Number of test samples: \" + str(self.X_test.shape[0]))\n",
    "        \n",
    "        \n",
    "    def simple_interpolation(self, model, params=None):\n",
    "        if not params is None:\n",
    "            model.set_params(**params)\n",
    "            \n",
    "        score_train = model.train(self.X_train, self.y_train, eval_score=True)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Train MSE score: \" + str(score_train))\n",
    "            \n",
    "        self.predictions, score_test = model.predict(self.X_test, self.y_test, eval_score=True)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Test MSE score: \" + str(score_test))\n",
    "            \n",
    "        return score_train, score_test\n",
    "            \n",
    "\n",
    "    def simple_optimization(self, model, param_grid, cv=None, n_restart=5):\n",
    "        if self.report:\n",
    "            bestc, bests, CV_res = model.optimize(self.X_train, self.y_train, cv=cv, \n",
    "                                    n_splits=n_restart, info=True, **param_grid)\n",
    "            CV_res.to_csv(self.report_path + '/CV_%s.csv' % model.get_name())\n",
    "        else:\n",
    "            bestc, bests = model.optimize(self.X_train, self.y_train, cv=cv, \n",
    "                                    n_splits=n_restart, info=True, **param_grid)\n",
    "            \n",
    "        return bestc, bests\n",
    "            \n",
    "    def benchmark(self, model_list, param_grid_list, optim=False, cv=None, n_restart=5):\n",
    "        if self.report:\n",
    "            save = pd.DataFrame(columns=['Name', 'Train Score', 'Test Score', 'Parameters', 'Database'])\n",
    "            \n",
    "        for i in range(0, len(model_list)):\n",
    "            model = model_list[i]\n",
    "            \n",
    "            if optim:\n",
    "                params = param_grid_list[i]\n",
    "                print(params)\n",
    "                model_parameters, score_train = self.simple_optimization(model, params, cv=cv, n_restart=n_restart)\n",
    "                self.predictions, score_test = model.predict(self.X_test, self.y_test, eval_score=True)\n",
    "                model_name = model.to_string()\n",
    "                model_parameters = str(model_parameters)\n",
    "                \n",
    "            else:\n",
    "                if not param_grid_list is None:\n",
    "                    params = param_grid_list[i]\n",
    "                else:\n",
    "                    params = None\n",
    "                score_train, score_test = self.simple_interpolation(model, params)\n",
    "                model_name, model_parameters = model.to_string()\n",
    "                \n",
    "            if self.report:\n",
    "                save.loc[i] = [model_name, score_train, score_test, model_parameters, datafile]\n",
    "        \n",
    "        if self.report:\n",
    "            save.to_csv(self.report_path + '/Benchmark.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition data into train and test samples\n",
      "Number of train samples: 754\n",
      "Number of test samples: 189\n"
     ]
    }
   ],
   "source": [
    "datafile = \"Temp-2019_01_04-15_47.csv\"\n",
    "pipe = Pipeline(data_file=datafile, verbose=True, report=True)\n",
    "pipe.partition_train_test(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE score: -0.0\n",
      "Test MSE score: -8.38585714286\n",
      "Train MSE score: -0.0\n",
      "Test MSE score: -8.38585714286\n",
      "Train MSE score: -1.09400521058\n",
      "Test MSE score: -6.72630882237\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    CustomModels.NearestNeighbor(),\n",
    "    CustomModels.InverseDistanceWeighting(),\n",
    "    CustomModels.RandomForest(),\n",
    "]\n",
    "param_grid_list = [\n",
    "    {\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'radius' : 10\n",
    "    },\n",
    "    {\n",
    "        'n_estimators' : 1000,\n",
    "        'max_depth' : 10\n",
    "    }\n",
    "]\n",
    "pipe.benchmark(model_list, param_grid_list, optim=False, cv=None, n_restart=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'radius': [10, 100, 1000]}\n",
      "{}\n",
      "{}\n",
      "{'max_depth': [9, 10, 11]}\n",
      "{'n_estimators': [1000, 5000], 'max_depth': [9, 10, 11]}\n",
      "{'n_estimators': [1000, 5000], 'max_depth': [9, 10, 11]}\n",
      "{'epsilon': [0.0001, 0.001, 0.01, 0.1], 'C': [1.0, 10, 100.0], 'gamma': [0.004, 0.02, 0.1]}\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    CustomModels.NearestNeighbor(),\n",
    "    CustomModels.InverseDistanceWeighting(),\n",
    "    CustomModels.GaussianProcess(),\n",
    "    CustomModels.GeographicallyWeightedRegressor(),\n",
    "    CustomModels.RegressionTree(),\n",
    "    CustomModels.RandomForest(),\n",
    "    CustomModels.ExtraTrees(),\n",
    "    CustomModels.SupportVectorRegression()\n",
    "]\n",
    "param_grid_list = [\n",
    "    {\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'radius' : [10, 100, 1000]\n",
    "    },\n",
    "    {\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'max_depth' : [9, 10, 11]\n",
    "    },\n",
    "    {\n",
    "        'n_estimators' : [1000, 5000],\n",
    "        'max_depth' : [9, 10, 11]\n",
    "    },\n",
    "    {\n",
    "        'n_estimators' : [1000, 5000],\n",
    "        'max_depth' : [9, 10, 11]\n",
    "    },\n",
    "    {\n",
    "        'gamma' : [0.004, 0.02, 0.1],\n",
    "        'C' : [1.0, 10, 1e2],\n",
    "        'epsilon' : [0.0001, 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'max_degree' : [3, 4, 5],\n",
    "        'penalty' : [1.0, 3.0, 9.0]\n",
    "    }\n",
    "]\n",
    "pipe.benchmark(model_list, param_grid_list, optim=True, cv='ShuffleSplit', n_restart=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-84fd9c9a7392>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##Read cities list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Temp-2019_01_04-15_47.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_learn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_learn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m##Create report folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "##Read cities list\n",
    "datafile = \"Temp-2019_01_04-15_47.csv\"\n",
    "X_learn, y_learn = load_data(datafile)\n",
    "\n",
    "##Create report folder\n",
    "report_path = create_report_folder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Map boundaries\n",
    "lon_min = -15.56\n",
    "lat_min = 24.65\n",
    "lon_max = 49.88\n",
    "lat_max = 79.17\n",
    "\n",
    "##Create map\n",
    "map = Basemap(llcrnrlon=lon_min,llcrnrlat=lat_min,urcrnrlon=lon_max,urcrnrlat=lat_max, resolution = 'l', epsg=4668)\n",
    "\n",
    "##Interpolation resolution\n",
    "nx = 100\n",
    "ny = 100\n",
    "\n",
    "glons, glats = map.makegrid(nx, ny)\n",
    "gx, gy = map(glons, glats)\n",
    "\n",
    "##Format data for interpolation\n",
    "#X_learn, y_learn = format_for_learning(lat, lon, temps)\n",
    "grid = format_grid_for_prediction(glats, glons)\n",
    "\n",
    "##Partition data between train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_learn, y_learn, test_size=0.2)\n",
    "print(\"Number of train samples: \" + str(X_train.shape[0]))\n",
    "print(\"Number of test samples: \" + str(X_test.shape[0]))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "##Choose the interpolation model\n",
    "model_list = [\n",
    "    CustomModels.NearestNeighbor(),\n",
    "    CustomModels.InverseDistanceWeighting(),\n",
    "    CustomModels.GaussianProcess(),\n",
    "    CustomModels.GeographicallyWeightedRegressor(),\n",
    "    CustomModels.RegressionTree(),\n",
    "    CustomModels.RandomForest(),\n",
    "    CustomModels.ExtraTrees(),\n",
    "    CustomModels.SupportVectorRegression()\n",
    "]\n",
    "\n",
    "#CV_Reports = {}\n",
    "#test_model = CustomModels.SupportVectorRegression()\n",
    "#param_grid = {\n",
    "#    'gamma' : [0.004, 0.02, 0.1],\n",
    "#    'C' : [1.0, 10, 1e2],\n",
    "#    'epsilon' : [0.0001, 0.001, 0.01, 0.1]\n",
    "#}\n",
    "#bestc, bests, CV_res = test_model.optimize(X_train, y_train, cv='ShuffleSplit', \n",
    "#                                             n_splits = 5, info=True, **param_grid)\n",
    "#CV_Reports[test_model.get_name()] = CV_res\n",
    "\n",
    "save = pd.DataFrame(columns=['Name', 'Train Score', 'Test Score', 'Parameters', 'Database'])\n",
    "for i in range(0, len(model_list)):\n",
    "    model = model_list[i]\n",
    "    model_name, model_parameters = model.to_string()\n",
    "    score_train = model.train(X_train, y_train, eval_score=True)\n",
    "    print(\"Train MSE score: \" + str(score_train))\n",
    "    preds, score_test = model.predict(X_test, y_test, eval_score=True)\n",
    "    print(\"Test MSE score: \" + str(score_test))\n",
    "    preds = model.predict(grid)\n",
    "    save.loc[i] = [model_name, score_train, score_test, model_parameters, datafile]\n",
    "    \n",
    "print(save)\n",
    "toc = time.time()\n",
    "print(\"Time: \" + str(1000*(toc-tic)) + \"ms\")\n",
    "\n",
    "##Format the predictions for plotting\n",
    "predict = format_prediction_to_grid(preds, nx, ny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,24))\n",
    "\n",
    "map.drawmapboundary(fill_color='white')\n",
    "#map.fillcontinents(color='coral',lake_color='white')\n",
    "map.drawcoastlines()\n",
    "\n",
    "lon = X_learn[:,1]\n",
    "lat = X_learn[:,0]\n",
    "temps = y_learn[:,0]\n",
    "x, y = map(lon, lat)\n",
    "cities_out_bounds = []\n",
    "\n",
    "##Create annotations for temperature and only keep cities in bound\n",
    "for i in range(0,len(x)):\n",
    "    if lon[i] > lon_min and lon[i] < lon_max and lat[i] > lat_min and lat[i] < lat_max:\n",
    "        plt.text(x[i], y[i], \"{0:.1f}\".format(temps[i]),fontsize=10,fontweight='bold', ha='center',va='center',color='k')\n",
    "\n",
    "##Plot contours\n",
    "clevs = [-24,-22,-20,-18,-16,-14,-12,-10,-8,-6,-4,-2,0,2,4,6,8,10,12,14,16,18,20,22]\n",
    "cs = map.contourf(gx,gy,predict,clevs,cmap='Spectral_r')\n",
    "\n",
    "##Display colorbar\n",
    "cbar = map.colorbar(cs,location='bottom',pad=\"5%\")\n",
    "cbar.set_label('degrees Celsius')\n",
    "\n",
    "##Getting the limits of the map:\n",
    "x0,x1 = ax.get_xlim()\n",
    "y0,y1 = ax.get_ylim()\n",
    "map_edges = np.array([[x0,y0],[x1,y0],[x1,y1],[x0,y1]])\n",
    "\n",
    "##Getting all polygons used to draw the coastlines of the map\n",
    "polys = [p.boundary for p in map.landpolygons]\n",
    "\n",
    "##Combining with map edges\n",
    "polys = [map_edges]+polys[:]\n",
    "\n",
    "##Creating a PathPatch\n",
    "codes = [\n",
    "    [Path.MOVETO] + [Path.LINETO for p in p[1:]]\n",
    "    for p in polys\n",
    "]\n",
    "polys_lin = [v for p in polys for v in p]\n",
    "codes_lin = [c for cs in codes for c in cs]\n",
    "path = Path(polys_lin, codes_lin)\n",
    "patch = PathPatch(path,facecolor='cyan',lw=0)\n",
    "\n",
    "##Masking the data:\n",
    "ax.add_patch(patch)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, report in CV_Reports.iteritems():\n",
    "#    report.to_csv(report_path + '/CV_%s.csv' % name)\n",
    "save.to_csv(report_path + '/Benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "toc = time.time()\n",
    "print(\"Time: \" + str(1000*(toc-tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[['Lat', 'Lon']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
