{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib.patches import Path, PathPatch\n",
    "import time, datetime\n",
    "import CustomKernels, CustomModels\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from importlib import import_module\n",
    "\n",
    "##Formatting functions\n",
    "def format_for_learning(xlat, xlon, temp):\n",
    "    X = np.column_stack((xlat, xlon))\n",
    "    Y = np.asarray(temp).reshape(len(temp),1)\n",
    "    return X, Y\n",
    "\n",
    "def format_grid_for_prediction(ylat, ylon):\n",
    "    grid = np.column_stack((np.hstack((ylat)),np.hstack((ylon))))\n",
    "    return grid\n",
    "    \n",
    "def format_prediction_to_grid(prediction, nrow, ncol):\n",
    "    matrix = np.reshape(prediction, (nrow,ncol))  \n",
    "    return matrix\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    report_path = \"\"\n",
    "    data_path = \"data/current-version/\"\n",
    "    datafile = \"\"\n",
    "    report = False\n",
    "    verbose = False\n",
    "    \n",
    "    def __init__(self, data_path=\"data/current-version/\", data_file=None, verbose=False, report=False):\n",
    "        if report:\n",
    "            self._create_report_folder()\n",
    "        self.data_path = data_path\n",
    "        if not data_file is None:\n",
    "            self.load_data(data_file)\n",
    "        self.verbose = verbose\n",
    "        self.report = report\n",
    "\n",
    "    def load_data(self, filename):\n",
    "        self.datafile = filename\n",
    "        df = pd.read_csv(self.data_path + self.datafile, ',')\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "        self.X_all = df[['Lat', 'Lon']].values\n",
    "        self.y_all = df[['Temp']].values\n",
    "\n",
    "    def _create_report_folder(self):\n",
    "        t = datetime.datetime.now()\n",
    "        self.report_path = 'reports/{0:%Y_%m_%d-%H_%M_%S}'.format(t)\n",
    "        os.mkdir(self.report_path)\n",
    "\n",
    "    def partition_train_test(self, test_size=0.2):\n",
    "        if self.verbose:\n",
    "            print(\"Partition data into train and test samples\")\n",
    "            \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X_all, \n",
    "                                                                                self.y_all, test_size=0.2)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Number of train samples: \" + str(self.X_train.shape[0]))\n",
    "            print(\"Number of test samples: \" + str(self.X_test.shape[0]))\n",
    "        \n",
    "        \n",
    "    def simple_interpolation(self, model, params=None):\n",
    "        if not params is None:\n",
    "            model.set_params(**params)\n",
    "            \n",
    "        score_train = model.train(self.X_train, self.y_train, eval_score=True)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Train MSE score: \" + str(score_train))\n",
    "            \n",
    "        self.predictions, score_test = model.predict(self.X_test, self.y_test, eval_score=True)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Test MSE score: \" + str(score_test))\n",
    "            \n",
    "        return score_train, score_test\n",
    "            \n",
    "\n",
    "    def simple_optimization(self, model, param_grid, cv=None, n_restart=5):\n",
    "        if self.report:\n",
    "            bestc, bests, CV_res = model.optimize(self.X_train, self.y_train, cv=cv, \n",
    "                                    n_splits=n_restart, info=True, **param_grid)\n",
    "            CV_res.to_csv(self.report_path + '/CV_%s.csv' % model.get_name())\n",
    "        else:\n",
    "            bestc, bests = model.optimize(self.X_train, self.y_train, cv=cv, \n",
    "                                    n_splits=n_restart, info=True, **param_grid)\n",
    "            \n",
    "        return bestc, bests\n",
    "            \n",
    "    def benchmark(self, model_list, param_grid_list=None, optim=False, cv=None, n_restart=5):\n",
    "        if self.report:\n",
    "            save = pd.DataFrame(columns=['Model', 'Train Score', 'Test Score', 'Parameters', 'Database'])\n",
    "            \n",
    "        for i in range(0, len(model_list)):\n",
    "            model = model_list[i]\n",
    "            \n",
    "            if optim:\n",
    "                params = param_grid_list[i]\n",
    "                print(params)\n",
    "                model_parameters, score_train = self.simple_optimization(model, params, cv=cv, n_restart=n_restart)\n",
    "                self.predictions, score_test = model.predict(self.X_test, self.y_test, eval_score=True)\n",
    "                model_name = model.to_string()\n",
    "                model_parameters = str(model_parameters)\n",
    "                \n",
    "            else:\n",
    "                if not param_grid_list is None:\n",
    "                    params = param_grid_list[i]\n",
    "                else:\n",
    "                    params = None\n",
    "                score_train, score_test = self.simple_interpolation(model, params)\n",
    "                model_name, model_parameters = model.to_string()\n",
    "                \n",
    "            if self.report:\n",
    "                save.loc[i] = [model_name, score_train, score_test, model_parameters, datafile]\n",
    "        \n",
    "        if self.report:\n",
    "            save.to_csv(self.report_path + '/Benchmark.csv')\n",
    "            \n",
    "            \n",
    "    def load_models(self, file_path_name):\n",
    "        df = pd.read_csv(file_path_name, ',')\n",
    "        df['Parameters'] = df['Parameters'].apply(ast.literal_eval)\n",
    "        df['Model'] = 'CustomModels.' + df['Model']\n",
    "        for idx, model in df['Model'].iteritems():\n",
    "            df.loc[idx, 'Model'] = eval(model)()\n",
    "            df.loc[idx, 'Model'].set_params(**df.loc[idx, 'Parameters'])\n",
    "            \n",
    "        model_list = df['Model'].values\n",
    "        \n",
    "        return model_list\n",
    "\n",
    "    def plot(self, model, nx=100, ny=100):\n",
    "        plotter = Plotter(nx=nx, ny=ny)\n",
    "        plotter.plot_map(model, self.X_all, self.y_all)\n",
    "        \n",
    "        \n",
    "class Plotter:\n",
    "    \n",
    "    ##Map boundaries\n",
    "    lon_min = -15.56\n",
    "    lat_min = 24.65\n",
    "    lon_max = 49.88\n",
    "    lat_max = 79.17\n",
    "    \n",
    "    def __init__(self, lon_min = -15.56, lat_min = 24.65, lon_max = 49.88, lat_max = 79.17, \n",
    "                 resolution = 'l', epsg = 4668, nx = 100, ny = 100):\n",
    "        \n",
    "        self.lon_min = lon_min\n",
    "        self.lat_min = lat_min\n",
    "        self.lon_max = lon_max\n",
    "        self.lat_max = lat_max\n",
    "        self._create_map(resolution=resolution, epsg=epsg)\n",
    "        self._create_grid(nx, ny)\n",
    "        self.predict = np.empty([nx, ny])\n",
    "        \n",
    "    def plot_map(self, model, X, Y):\n",
    "        self._predict_grid(model)\n",
    "        \n",
    "        self.fig, self.ax = plt.subplots(figsize=(24,24))\n",
    "        \n",
    "        self.m.drawmapboundary(fill_color='white')\n",
    "        self.m.drawcoastlines()\n",
    "        \n",
    "        self._draw_annotations(X, Y)\n",
    "        \n",
    "        self._plot_contours()\n",
    "        patch = self._mask_ocean()\n",
    "        self.ax.add_patch(patch)\n",
    "        plt.show()\n",
    "        \n",
    "    def _create_map(self, resolution = 'l', epsg = 4668):\n",
    "        self.m = Basemap(llcrnrlon = self.lon_min, llcrnrlat = self.lat_min, urcrnrlon = self.lon_max, urcrnrlat = self.lat_max, \n",
    "                      resolution = resolution, epsg = epsg)\n",
    "\n",
    "    def _create_grid(self, nx, ny):\n",
    "        glons, glats = self.m.makegrid(nx, ny)\n",
    "        self.gx, self.gy = self.m(glons, glats)\n",
    "        self.grid = format_grid_for_prediction(glats, glons)\n",
    "\n",
    "    def _predict_grid(self, model):\n",
    "        preds = model.predict(self.grid)\n",
    "        self.predict = format_prediction_to_grid(preds, self.predict.shape[0], self.predict.shape[1])\n",
    "        \n",
    "    def _draw_annotations(self, X, Y):\n",
    "        lon = X[:,1]\n",
    "        lat = X[:,0]\n",
    "        temps = Y[:,0]\n",
    "        x, y = self.m(lon, lat)\n",
    "        \n",
    "        for i in range(0, len(x)):\n",
    "            if lon[i] > self.lon_min and lon[i] < self.lon_max and lat[i] > self.lat_min and lat[i] < self.lat_max:\n",
    "                plt.text(x[i], y[i], \"{0:.1f}\".format(temps[i]),fontsize=10,fontweight='bold', ha='center',va='center',color='k')\n",
    "        \n",
    "    def _plot_contours(self):\n",
    "        clevs = [-24,-22,-20,-18,-16,-14,-12,-10,-8,-6,-4,-2,0,2,4,6,8,10,12,14,16,18,20,22]\n",
    "        cs = self.m.contourf(self.gx, self.gy, self.predict, clevs, cmap='Spectral_r')\n",
    "        \n",
    "        cbar = self.m.colorbar(cs,location='bottom',pad=\"5%\")\n",
    "        cbar.set_label('degrees Celsius')\n",
    "        \n",
    "    def _mask_ocean(self):\n",
    "        ##Getting the limits of the map:\n",
    "        x0,x1 = self.ax.get_xlim()\n",
    "        y0,y1 = self.ax.get_ylim()\n",
    "        map_edges = np.array([[x0,y0],[x1,y0],[x1,y1],[x0,y1]])\n",
    "    \n",
    "        ##Getting all polygons used to draw the coastlines of the map\n",
    "        polys = [p.boundary for p in self.m.landpolygons]\n",
    "    \n",
    "        ##Combining with map edges\n",
    "        polys = [map_edges]+polys[:]\n",
    "    \n",
    "        ##Creating a PathPatch\n",
    "        codes = [\n",
    "            [Path.MOVETO] + [Path.LINETO for p in p[1:]]\n",
    "            for p in polys\n",
    "        ]\n",
    "        polys_lin = [v for p in polys for v in p]\n",
    "        codes_lin = [c for cs in codes for c in cs]\n",
    "        path = Path(polys_lin, codes_lin)\n",
    "        patch = PathPatch(path,facecolor='cyan',lw=0)\n",
    "        return patch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"Temp-2019_01_04-15_47.csv\"\n",
    "pipe = Pipeline(data_file=datafile, verbose=True, report=True)\n",
    "pipe.partition_train_test(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_list = [\n",
    "#    CustomModels.NearestNeighbor(),\n",
    "#    CustomModels.InverseDistanceWeighting(),\n",
    "#    CustomModels.RandomForest(),\n",
    "#]\n",
    "#param_grid_list = [\n",
    "#    {\n",
    "#        \n",
    "#    },\n",
    "#    {\n",
    "#        'radius' : 10\n",
    "#    },\n",
    "#    {\n",
    "#        'n_estimators' : 1000,\n",
    "#        'max_depth' : 10\n",
    "#    }\n",
    "#]\n",
    "#pipe.benchmark(model_list, param_grid_list, optim=False, cv=None, n_restart=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_list = [\n",
    "#    CustomModels.NearestNeighbor(),\n",
    "#    CustomModels.InverseDistanceWeighting(),\n",
    "#    CustomModels.GaussianProcess(),\n",
    "#    CustomModels.GeographicallyWeightedRegressor(),\n",
    "#    CustomModels.RegressionTree(),\n",
    "#    CustomModels.RandomForest(),\n",
    "#    CustomModels.ExtraTrees(),\n",
    "#    CustomModels.SupportVectorRegression()\n",
    "#]\n",
    "#param_grid_list = [\n",
    "#    {\n",
    "#        \n",
    "#    },\n",
    "#    {\n",
    "#        'radius' : [10, 100, 1000]\n",
    "#    },\n",
    "#    {\n",
    "#        \n",
    "#    },\n",
    "#    {\n",
    "#        \n",
    "#    },\n",
    "#    {\n",
    "#        'max_depth' : [9, 10, 11]\n",
    "#    },\n",
    "#    {\n",
    "#        'n_estimators' : [1000, 5000],\n",
    "#        'max_depth' : [9, 10, 11]\n",
    "#    },\n",
    "#    {\n",
    "#        'n_estimators' : [1000, 5000],\n",
    "#        'max_depth' : [9, 10, 11]\n",
    "#    },\n",
    "#    {\n",
    "#        'gamma' : [0.004, 0.02, 0.1],\n",
    "#        'C' : [1.0, 10, 1e2],\n",
    "#        'epsilon' : [0.0001, 0.001, 0.01, 0.1]\n",
    "#    },\n",
    "#    {\n",
    "#        'max_degree' : [3, 4, 5],\n",
    "#        'penalty' : [1.0, 3.0, 9.0]\n",
    "#    }\n",
    "#]\n",
    "#pipe.benchmark(model_list, param_grid_list, optim=True, cv='ShuffleSplit', n_restart=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist = pipe.load_models(\"reports/2019_01_10-22_03_14/Benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.benchmark(mlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in mlist:\n",
    "    pipe.plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
